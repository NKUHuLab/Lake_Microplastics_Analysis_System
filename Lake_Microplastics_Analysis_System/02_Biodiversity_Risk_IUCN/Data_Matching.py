import pandas as pd
import os

# --- æ–‡ä»¶è·¯å¾„é…ç½® ---
# ä½¿ç”¨æ‚¨æä¾›çš„ç»å¯¹è·¯å¾„
# æ³¨æ„ï¼šåœ¨Pythonä¸­ï¼Œæœ€å¥½ä½¿ç”¨æ­£æ–œæ  / æˆ–è€…åŒåæ–œæ  \\ æ¥è¡¨ç¤ºè·¯å¾„
small_file_path = r"E:\lake-MP-W\dataset\IUCN\bio\iucn_threatened_species_attributes.csv"
large_file_path = r"E:\lake-MP-W\dataset\IUCN\bio\all_freshwater_species_attributes.csv"
output_filename = r"E:\lake-MP-W\dataset\IUCN\bio\matched_species_output.csv"


# --------------------

def match_species_files(small_path, large_path, output_path):
    """
    åŠ è½½ä¸¤ä¸ªç‰©ç§å±æ€§CSVæ–‡ä»¶ï¼Œæ ¹æ®ç§‘å­¦åç§°è¿›è¡ŒåŒ¹é…ï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ°æ–°æ–‡ä»¶ã€‚
    """
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(small_path):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°å°æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„: '{small_path}'")
        return
    if not os.path.exists(large_path):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°å¤§æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„: '{large_path}'")
        return

    try:
        print("æ­¥éª¤ 1: å¼€å§‹åŠ è½½æ–‡ä»¶...")
        # åŠ è½½æ–‡ä»¶æ—¶ä½¿ç”¨ engine='python' ä»¥å¢åŠ å¯¹å¤æ‚CSVæ ¼å¼çš„å…¼å®¹æ€§
        # on_bad_lines='skip' ä¼šè·³è¿‡æ ¼å¼é”™è¯¯çš„è¡Œ
        small_df = pd.read_csv(small_path, engine='python', on_bad_lines='skip')
        print(f"  - æˆåŠŸåŠ è½½å°æ–‡ä»¶ (å…± {len(small_df)} è¡Œ)")

        large_df = pd.read_csv(large_path, engine='python', on_bad_lines='skip')
        print(f"  - æˆåŠŸåŠ è½½å¤§æ–‡ä»¶ (å…± {len(large_df)} è¡Œ)")
        print("-" * 30)

        # æ­¥éª¤ 2: å‡†å¤‡ç”¨äºåŒ¹é…çš„åˆ—
        # å°æ–‡ä»¶ä¸­çš„åˆ—åä¸º 'SCI_NAME', å¤§æ–‡ä»¶ä¸­ä¸º 'sci_name'
        print("æ­¥éª¤ 2: å‡†å¤‡ç”¨äºåŒ¹é…çš„åˆ—...")
        if 'SCI_NAME' not in small_df.columns:
            print(f"é”™è¯¯: å°æ–‡ä»¶ä¸­æœªæ‰¾åˆ° 'SCI_NAME' åˆ—ã€‚å¯ç”¨åˆ—: {small_df.columns.tolist()}")
            return
        if 'sci_name' not in large_df.columns:
            print(f"é”™è¯¯: å¤§æ–‡ä»¶ä¸­æœªæ‰¾åˆ° 'sci_name' åˆ—ã€‚å¯ç”¨åˆ—: {large_df.columns.tolist()}")
            return

        small_df_renamed = small_df.rename(columns={'SCI_NAME': 'sci_name'})
        print("  - å·²å°†å°æ–‡ä»¶ä¸­çš„ 'SCI_NAME' åˆ—é‡å‘½åä¸º 'sci_name' ä»¥è¿›è¡ŒåŒ¹é…ã€‚")
        print("-" * 30)

        # æ­¥éª¤ 3: ç»Ÿä¸€å…³é”®åˆ—çš„æ•°æ®ç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œè¿™æ˜¯é¿å…åˆå¹¶é”™è¯¯çš„å…³é”®
        print("æ­¥éª¤ 3: ç»Ÿä¸€ 'sci_name' åˆ—çš„æ•°æ®ç±»å‹ä¸ºå­—ç¬¦ä¸²...")
        small_df_renamed['sci_name'] = small_df_renamed['sci_name'].astype(str)
        large_df['sci_name'] = large_df['sci_name'].astype(str)
        print("  - æ•°æ®ç±»å‹å·²ç»Ÿä¸€ã€‚")
        print("-" * 30)

        # æ­¥éª¤ 4: æ‰§è¡ŒåŒ¹é…æ“ä½œ (inner join)
        print("æ­¥éª¤ 4: å¼€å§‹åŒ¹é…ä¸¤ä¸ªæ–‡ä»¶ä¸­çš„ç‰©ç§åç§°...")
        # ä½¿ç”¨ sufrefinees å‚æ•°æ¥åŒºåˆ†æ¥è‡ªä¸åŒæ–‡ä»¶çš„åŒååˆ—
        matched_df = pd.merge(large_df, small_df_renamed, on='sci_name', how='inner', suffixes=('_large', '_small'))
        print("  - åŒ¹é…å®Œæˆã€‚")
        print("-" * 30)

        # æ­¥éª¤ 5: ä¿å­˜å¹¶æŠ¥å‘Šç»“æœ
        print("æ­¥éª¤ 5: ä¿å­˜ç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š...")
        # ä½¿ç”¨ utf-8-sig ç¼–ç ä»¥ç¡®ä¿åœ¨Excelä¸­æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡ç­‰å­—ç¬¦
        matched_df.to_csv(output_path, index=False, encoding='utf-8-sig')

        print("\nğŸ‰ æ“ä½œæˆåŠŸå®Œæˆï¼ ğŸ‰")
        if not matched_df.empty:
            print(f"åœ¨ä¸¤ä¸ªæ–‡ä»¶ä¸­æ‰¾åˆ°äº† {len(matched_df)} æ¡å®Œå…¨åŒ¹é…çš„ç‰©ç§è®°å½•ã€‚")
            print(f"è¯¦ç»†åŒ¹é…ç»“æœå·²ä¿å­˜åˆ°æ–‡ä»¶: '{output_path}'")
        else:
            print("æ“ä½œå®Œæˆï¼Œä½†åœ¨ä¸¤ä¸ªæ–‡ä»¶ä¹‹é—´æœªæ‰¾åˆ°ä»»ä½•å…±åŒçš„ç‰©ç§åç§°ã€‚")

    except Exception as e:
        print(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿäº†ä¸€ä¸ªæœªé¢„æ–™çš„é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥æ‚¨çš„CSVæ–‡ä»¶å†…å®¹å’Œæ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")


# --- æ‰§è¡Œä¸»å‡½æ•° ---
if __name__ == "__main__":
    match_species_files(small_file_path, large_file_path, output_filename)